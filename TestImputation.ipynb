{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import os\n",
    "\n",
    "from scipy import signal\n",
    "from scipy import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import models.models_mae as models_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_all_seqs(dir='../data', files=None):\n",
    "    if files is None:\n",
    "        files = map(lambda filename: dir + '/' + filename, os.listdir(dir))\n",
    "\n",
    "    seqs = []\n",
    "    for filename in files:\n",
    "        with h5py.File(filename, 'r') as f:\n",
    "            seqs.extend([f[h5py.h5r.get_name(elem, f.id)][:] for elem in f['chirp_sequence_array']])\n",
    "\n",
    "    return seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample(use_wav_example=false, seq_idx=200):\n",
    "    if use_wav_example:\n",
    "        _, Y = io.wavfile.read('./audioset/Y__p-iA312kg.wav')\n",
    "        return Y\n",
    "    seqs = read_all_seqs()\n",
    "    X = seqs[seq_idx].T[:, 0:4]\n",
    "\n",
    "    upsample_rate = 110 // 15 #match upper range of bat hearing to approx. upper range of human hearing\n",
    "\n",
    "    x = signal.resample(X[:, 0], X.shape[0] * upsample_rate)\n",
    "    x = x * signal.windows.hamming(len(x))\n",
    "    x = np.hstack((x, np.zeros(320299 - len(x_cpu))))\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mel_spectrogram(self, x, model):\n",
    "    old_shape = x.size()\n",
    "    x = x.reshape(-1, old_shape[2])\n",
    "    x = model.mel(x)\n",
    "    x = (x - model.frame_mean[None, :, None]) / model.frame_std[None, :, None]\n",
    "    x = x.reshape(old_shape[0], old_shape[1], x.shape[1], x.shape[2])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model_forward(x, model, device, mask_ratio=0.75):\n",
    "    model = model.to(device)\n",
    "\n",
    "    x = torch.from_numpy(x.reshape(1, 1, -1).astype('float32'))\n",
    "    x = x.to(device)\n",
    "    x = x.type(torch.FloatTensor).cuda()\n",
    "\n",
    "    mel_x = mel_spectrogram(x, model)\n",
    "    mel_x_cpu = mel_x.detach().cpu()[0][0].numpy()\n",
    "\n",
    "    loss, pred, mask = model.forward(x, 0.1)\n",
    "    x_prime = model.unpatchify(pred[:, :, :, np.newaxis])\n",
    "    \n",
    "    return mel_x_cpu, x_prime, loss, mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_specgram(Sx):\n",
    "    plt.figure(figsize=(15, 4))\n",
    "    plt.imshow(np.flip(Sx, axis=0), aspect='auto')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_imputation(x, model, device, patch_mask):\n",
    "    mel_x = mel_spectrogram(x, model)\n",
    "    mel_x = mel_x[:, :, :model.patch_embed.img_size[0], :model.patch_embed.img_size[1]] \n",
    "    mel_x = model.patch_embed(mel_x)\n",
    "    mel_x = mel_x + model.pos_embed[:, 1:, :]\n",
    "\n",
    "    D = mel_x.shape[3]\n",
    "\n",
    "    ids_keep = torch.nonzero(patch_mask, as_tuple=True)[0]\n",
    "    ids_mask = torch.nonzero(1 - patch_mask, as_tuple=True)[0]\n",
    "    ids_restore = torch.cat((ids_keep, ids_mask))\n",
    "    \n",
    "    mel_x_masked = torch.gather(mel_x, dim=1, index=ids_keep.unsqueeze(-1).repeat(1, 1, D))\n",
    "\n",
    "    cls_token = model.cls_token + model.pos_embed[:, :1, :]\n",
    "    cls_tokens = cls_token.expand(mel_x_masked.shape[0], -1, -1)\n",
    "    mel_x_masked = torch.cat((cls_tokens, mel_x_masked), dim=1)\n",
    "\n",
    "    # apply Transformer blocks\n",
    "    for blk in model.blocks:\n",
    "        x = blk(x)\n",
    "    x = model.norm(x)\n",
    "\n",
    "    pred = model.forward_decoder(latent, ids_restore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setup pytorch\n",
    "\n",
    "GPU_NUM = '0'\n",
    "\n",
    "device = torch.device(('cuda:' + GPU_NUM) if (torch.cuda.is_available() and GPU_NUM != '-1') else 'cpu')\n",
    "print(\"Using device: {}\".format(device))\n",
    "if device == 'cuda':\n",
    "    print(\"Device index: {}\".format(torch.cuda.current_device()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.forward_decoder(latent, ids_restore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.forward_loss(mel_x, pred, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_prime = model.unpatchify(pred[:, :, :, np.newaxis])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
